{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ffb29c8",
   "metadata": {},
   "source": [
    "# Telco Customer Churn — End-to-End Case Study\n",
    "\n",
"**Author:** Najam us Sahar\n",
    "**Goal:** Build an end-to-end churn analysis from raw data - insights - modelling - recommendations.\n",
    "\n",
    "Dataset: Telco Customer Churn (Excel)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719cecfd",
   "metadata": {},
   "source": [
    "## 1) Problem framing\n",
    "**What is churn here?** A customer who **cancels service** (target column `Churn` = `Yes`).\n",
    "\n",
    "**Why it matters:** churn reduces recurring revenue, increases acquisition costs (replacing lost customers), and often signals product/service gaps. Measuring churn helps prioritize retention interventions and forecast revenue risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cc6299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_PATH = \"WA_Fn-UseC_-Telco-Customer-Churn 2.xlsx\"\n",
    "df = pd.read_excel(DATA_PATH)\n",
    "df.shape, df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfc1fd3",
   "metadata": {},
   "source": [
    "## 2) Data cleaning & preparation\n",
    "- Handle missing values (notably `TotalCharges` contains blanks).\n",
    "- Fix data types.\n",
    "- Validate the target (`Churn`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b9bb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy()\n",
    "\n",
    "# Fix TotalCharges: convert to numeric (blanks -> NaN)\n",
    "df_clean[\"TotalCharges\"] = pd.to_numeric(df_clean[\"TotalCharges\"], errors=\"coerce\")\n",
    "\n",
    "missing = df_clean.isna().sum().sort_values(ascending=False)\n",
    "missing.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3abee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[\"Churn\"].value_counts(), df_clean[\"Churn\"].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128024fe",
   "metadata": {},
   "source": [
    "## 3) Exploratory Data Analysis (EDA)\n",
    "We’ll compare churn vs non-churn customers across:\n",
    "- tenure\n",
    "- monthly charges\n",
    "- contract type\n",
    "- internet service type\n",
    "- key add-on services (security/support)\n",
    "\n",
    "### 3.1 Overall churn rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f8e91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_rate = (df_clean[\"Churn\"]==\"Yes\").mean()\n",
    "churn_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18da638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tenure distribution by churn\n",
    "plt.figure()\n",
    "df_clean[df_clean[\"Churn\"]==\"No\"][\"tenure\"].hist(bins=30, alpha=0.7, label=\"No\")\n",
    "df_clean[df_clean[\"Churn\"]==\"Yes\"][\"tenure\"].hist(bins=30, alpha=0.7, label=\"Yes\")\n",
    "plt.title(\"Tenure distribution by churn\")\n",
    "plt.xlabel(\"Tenure (months)\")\n",
    "plt.ylabel(\"Customers\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d15ea13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly charges by churn\n",
    "plt.figure()\n",
    "df_clean[df_clean[\"Churn\"]==\"No\"][\"MonthlyCharges\"].hist(bins=30, alpha=0.7, label=\"No\")\n",
    "df_clean[df_clean[\"Churn\"]==\"Yes\"][\"MonthlyCharges\"].hist(bins=30, alpha=0.7, label=\"Yes\")\n",
    "plt.title(\"MonthlyCharges distribution by churn\")\n",
    "plt.xlabel(\"MonthlyCharges\")\n",
    "plt.ylabel(\"Customers\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e50670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Churn rate by Contract / InternetService / PaymentMethod\n",
    "def churn_by(col):\n",
    "    return df_clean.groupby(col)[\"Churn\"].apply(lambda s: (s==\"Yes\").mean()).sort_values(ascending=False)\n",
    "\n",
    "for col in [\"Contract\",\"InternetService\",\"PaymentMethod\",\"TechSupport\",\"OnlineSecurity\"]:\n",
    "    print(\"\\n\", col)\n",
    "    display(churn_by(col))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9897f4f0",
   "metadata": {},
   "source": [
    "## 4) Feature engineering\n",
    "Create features that may help explain churn:\n",
    "- `tenure_group` buckets\n",
    "- `avg_monthly_spend` (TotalCharges/tenure with safe fallback)\n",
    "- `services_count` (how many add-on services are active)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5435da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = df_clean.copy()\n",
    "\n",
    "fe[\"tenure_group\"] = pd.cut(\n",
    "    fe[\"tenure\"],\n",
    "    bins=[-1, 0, 12, 24, 48, 72],\n",
    "    labels=[\"0\",\"1-12\",\"13-24\",\"25-48\",\"49-72\"]\n",
    ")\n",
    "\n",
    "fe[\"avg_monthly_spend\"] = fe[\"TotalCharges\"] / (fe[\"tenure\"].replace(0, np.nan))\n",
    "fe[\"avg_monthly_spend\"] = fe[\"avg_monthly_spend\"].fillna(fe[\"MonthlyCharges\"])\n",
    "\n",
    "service_cols = [\n",
    "    \"PhoneService\",\"MultipleLines\",\"OnlineSecurity\",\"OnlineBackup\",\"DeviceProtection\",\n",
    "    \"TechSupport\",\"StreamingTV\",\"StreamingMovies\"\n",
    "]\n",
    "\n",
    "def yes_no_to_binary(s):\n",
    "    return s.replace({\"Yes\":1,\"No\":0,\"No phone service\":0,\"No internet service\":0})\n",
    "\n",
    "for c in service_cols:\n",
    "    fe[c+\"_bin\"] = yes_no_to_binary(fe[c])\n",
    "\n",
    "fe[\"services_count\"] = fe[[c+\"_bin\" for c in service_cols]].sum(axis=1)\n",
    "\n",
    "fe[[\"tenure\",\"tenure_group\",\"avg_monthly_spend\",\"services_count\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308fbc30",
   "metadata": {},
   "source": [
    "## 5) Churn modelling\n",
    "We will train **two** classification models:\n",
    "- Logistic Regression (interpretable baseline)\n",
    "- Random Forest (nonlinear model)\n",
    "\n",
    "Evaluation:\n",
    "- Confusion matrix\n",
    "- Precision / Recall\n",
    "- ROC-AUC\n",
    "\n",
    "**Note:** The dataset is imbalanced (~26.5% churn), so we use `class_weight='balanced'` variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae16d8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report,\n",
    "    roc_auc_score, RocCurveDisplay, PrecisionRecallDisplay,\n",
    "    precision_score, recall_score, f1_score, accuracy_score\n",
    ")\n",
    "\n",
    "y = fe[\"Churn\"].map({\"Yes\":1,\"No\":0})\n",
    "X = fe.drop(columns=[\"Churn\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "numeric_features = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = [c for c in X_train.columns if c not in numeric_features]\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "lr = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", LogisticRegression(max_iter=2000, class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "rf = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", RandomForestClassifier(\n",
    "        n_estimators=400, random_state=42, class_weight=\"balanced_subsample\",\n",
    "        min_samples_leaf=5, n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "lr_proba = lr.predict_proba(X_test)[:,1]\n",
    "rf_proba = rf.predict_proba(X_test)[:,1]\n",
    "lr_pred = (lr_proba>=0.5).astype(int)\n",
    "rf_pred = (rf_proba>=0.5).astype(int)\n",
    "\n",
    "def summarize(y_true, y_pred, y_proba):\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred),\n",
    "        \"recall\": recall_score(y_true, y_pred),\n",
    "        \"f1\": f1_score(y_true, y_pred),\n",
    "        \"roc_auc\": roc_auc_score(y_true, y_proba),\n",
    "        \"confusion_matrix\": confusion_matrix(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "lr_sum = summarize(y_test, lr_pred, lr_proba)\n",
    "rf_sum = summarize(y_test, rf_pred, rf_proba)\n",
    "\n",
    "lr_sum, rf_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb589b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logistic Regression\\n\", classification_report(y_test, lr_pred))\n",
    "print(\"Confusion matrix\\n\", lr_sum[\"confusion_matrix\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b874ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random Forest\\n\", classification_report(y_test, rf_pred))\n",
    "print(\"Confusion matrix\\n\", rf_sum[\"confusion_matrix\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9f6f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "RocCurveDisplay.from_predictions(y_test, lr_proba, name=\"LogReg\")\n",
    "RocCurveDisplay.from_predictions(y_test, rf_proba, name=\"RF\")\n",
    "plt.title(\"ROC Curves\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "PrecisionRecallDisplay.from_predictions(y_test, lr_proba, name=\"LogReg\")\n",
    "PrecisionRecallDisplay.from_predictions(y_test, rf_proba, name=\"RF\")\n",
    "plt.title(\"Precision-Recall Curves\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98046719",
   "metadata": {},
   "source": [
    "## 6) Postdictive analysis (predicted vs actual)\n",
    "Where does the model do well and where does it fail?\n",
    "- **False Negatives (FN):** customers who churned but the model missed them.\n",
    "- **False Positives (FP):** customers predicted to churn but they did not.\n",
    "\n",
    "We inspect probability scores and segment patterns for errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaec14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = X_test.copy()\n",
    "pred_df[\"actual_churn\"] = y_test.values\n",
    "pred_df[\"proba_churn\"] = lr_proba\n",
    "pred_df[\"pred_churn\"] = lr_pred\n",
    "\n",
    "pred_df[\"error_type\"] = np.where(\n",
    "    (pred_df[\"actual_churn\"]==1) & (pred_df[\"pred_churn\"]==0), \"FN (missed churn)\",\n",
    "    np.where((pred_df[\"actual_churn\"]==0) & (pred_df[\"pred_churn\"]==1), \"FP (false alarm)\", \"Correct\")\n",
    ")\n",
    "\n",
    "pred_df[\"error_type\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf06984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability summary by error type\n",
    "pred_df.groupby(\"error_type\")[\"proba_churn\"].agg([\"count\",\"mean\",\"median\"]).sort_values(\"mean\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547fa7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where do false negatives cluster?\n",
    "for col in [\"Contract\",\"InternetService\",\"PaymentMethod\",\"tenure_group\"]:\n",
    "    print(\"\\nFN share by\", col)\n",
    "    display(pred_df[pred_df[\"error_type\"]==\"FN (missed churn)\"][col].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5fc1ce",
   "metadata": {},
   "source": [
    "## 7) Business recommendations\n",
    "Based on EDA + model behaviour, typical high-risk segments include:\n",
    "- Month-to-month contracts (highest churn)\n",
    "- Fiber optic internet customers with low perceived value (high churn)\n",
    "- Electronic check payers (highest churn)\n",
    "- Low-tenure customers (first 12 months)\n",
    "- Customers lacking **OnlineSecurity** and **TechSupport** add-ons\n",
    "\n",
    "### Recommended actions\n",
    "1. **Convert month-to-month → annual**: targeted offers at month 2–3 and month 10–12.\n",
    "2. **New-customer onboarding** (first 90 days): proactive support calls / setup help.\n",
    "3. **Value-pack bundles**: include security/support for fiber customers; test pricing.\n",
    "4. **Payment friction reduction**: incentivize auto-pay; investigate electronic check pain points.\n",
    "5. **Prioritize retention list**: score customers weekly; focus on top-decile risk.\n",
    "\n",
    "### Operating the model\n",
    "- Use churn probability thresholds depending on cost trade-offs.\n",
    "- For retention campaigns, consider **lowering threshold** to catch more churners (reducing FN) if outreach is cheap.\n",
    "- Track outcomes (saved vs churned) to continuously improve."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
